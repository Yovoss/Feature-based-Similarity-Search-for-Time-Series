{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file is to implement the designed feature-based similarity distance method\n",
    "# The cost function is defined as the square of discrepancy between DTW of two real time series and Euclidean of the\n",
    "# two time series in new feature space.\n",
    "# The input time series is re-scaled into [0,1]\n",
    "# Date: 9/29/2016\n",
    "# Author: Zexi Chen(zchen22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import six.moves.cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# samples1 file contains 10000 time series, and each one has 23 time points\n",
    "# It is used as the training data\n",
    "fileObject1 = open('../theano/data/samples1','r')\n",
    "train_set = pickle.load(fileObject1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample2 file contains 10000 time series, same format\n",
    "# It is used as the validation set\n",
    "fileObject2 = open('../theano/data/samples2','r')\n",
    "valid_set = pickle.load(fileObject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample3 file contains 10000 time series served as test data\n",
    "fileObject3 = open('../theano/data/samples3','r')\n",
    "test_set = pickle.load(fileObject3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape the array, concatenate two time series as one training instance\n",
    "train_set_reshape = numpy.reshape(train_set, (train_set.shape[0]/2, train_set.shape[1]*2))\n",
    "valid_set_reshape = numpy.reshape(valid_set, (valid_set.shape[0]/2, valid_set.shape[1]*2))\n",
    "test_set_reshape = numpy.reshape(test_set, (test_set.shape[0]/2, test_set.shape[1]*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-scale input data\n",
    "train_set1 = train_set_reshape/255.0\n",
    "valid_set1 = valid_set_reshape/255.0\n",
    "test_set1 = test_set_reshape/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define dtw function\n",
    "def dtw(list1, list2, window = 1):\n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    mat = [[float('inf') for x in range(len2 + 1)] for y in range(len1 + 1)]\n",
    "    mat[0][0] = 0\n",
    "    for i in range(1,len1 + 1):\n",
    "        if i - window <= 1:\n",
    "            start = 1\n",
    "        else:\n",
    "            start = i - window\n",
    "        \n",
    "        if i + window <= len2:\n",
    "            end = i + window\n",
    "        else:\n",
    "            end = len2\n",
    "        for j in range(start, end + 1):\n",
    "            cost = abs(float(list1[i - 1] - list2[j - 1]))\n",
    "            mat[i][j] = cost + min(mat[i-1][j], mat[i][j-1],mat[i-1][j-1])\n",
    "        \n",
    "    return mat[len1][len2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define euclidean distance function \n",
    "def euclideanDist(list1,list2):\n",
    "    distance = 0\n",
    "    for x in range(len(list1)):\n",
    "        distance += pow((list1[x]-list2[x]),2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the dtw distance between the two time series in each row of the training data validation data and test data \n",
    "# the dtw is used in the cost function as the target value to minimize\n",
    "train_dtws = numpy.zeros((train_set1.shape[0],1))\n",
    "for i in range(train_set1.shape[0]):\n",
    "    train_dtws[i,0] = dtw(train_set1[i,0:23], train_set1[i,23:])**2\n",
    "    \n",
    "valid_dtws = numpy.zeros((valid_set1.shape[0],1))\n",
    "for i in range(valid_set1.shape[0]):\n",
    "    valid_dtws[i,0] = dtw(valid_set1[i,0:23], valid_set1[i,23:])**2\n",
    "\n",
    "test_dtws = numpy.zeros((test_set1.shape[0],1))\n",
    "for i in range(test_set1.shape[0]):\n",
    "    test_dtws[i,0] = dtw(test_set1[i,0:23], test_set1[i,23:])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7fabe8979690>> ignored\n"
     ]
    }
   ],
   "source": [
    "# build the neural network model\n",
    "# start the tensorflow interaction interface\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the number of nerons in hidden layers\n",
    "numFeatureMaps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the flow graph. \n",
    "# create two variable placehold, x for the training features, \n",
    "# y for the labels(in this model it is the dtw distance between two time series)\n",
    "x = tf.placeholder(tf.float32, shape=[None, train_set1.shape[1]])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the weight matrix, initialize randomly \n",
    "# truncated_normal: output random values from a truncated normal distribution with value out of 2 sd dropped \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the bias\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape the training input to comform the CNN model [batch size, width, height, color channels]\n",
    "# x_ts = tf.to_float(x_ts)\n",
    "x_ts = tf.reshape(x, [-1,46,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the weight matrix and the bias\n",
    "# specify the filter size: [filter_width, filter_height, in_channels, out_channels]\n",
    "W_conv1 = weight_variable([23,1,1,numFeatureMaps])\n",
    "b_conv1 = bias_variable([numFeatureMaps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the model we use and set up the paratemers\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,23,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the cost function: (dtw-euclidean(timeseries1 new features, timeseries2 new features))^2\n",
    "h_conv1 = tf.nn.sigmoid(conv2d(x_ts, W_conv1) + b_conv1)\n",
    "h_conv1_flat = tf.reshape(h_conv1,[-1, 2 * numFeatureMaps])\n",
    "#h_conv1_flat_diff = tf.square(tf.sub(h_conv1_flat[:,:numFeatureMaps],h_conv1_flat[:,numFeatureMaps:]))\n",
    "h_conv1_flat_diff = tf.square(tf.sub(h_conv1_flat[:,:numFeatureMaps],h_conv1_flat[:,numFeatureMaps:]))\n",
    "#cost_function = tf.reduce_mean(tf.square(tf.sub(y_ ,tf.sqrt(tf.reduce_sum(h_conv1_flat_diff,1,keep_dims=True)))))\n",
    "cost_function = tf.reduce_mean(tf.square(tf.sub(y_ ,tf.reduce_sum(h_conv1_flat_diff,1,keep_dims=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the training optimizer for the model\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the model graph parameters\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_result = cost_function.eval(feed_dict={x:train_set1, y_:train_dtws})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.39238"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, the mean error of the training data 16.3924, vilidation data 16.1818\n",
      "step 100, the mean error of the training data 2.72997, vilidation data 2.46817\n",
      "step 200, the mean error of the training data 1.79494, vilidation data 1.74219\n",
      "step 300, the mean error of the training data 1.38327, vilidation data 1.48859\n",
      "step 400, the mean error of the training data 1.138, vilidation data 1.34102\n",
      "step 500, the mean error of the training data 0.961132, vilidation data 1.22811\n",
      "step 600, the mean error of the training data 0.8312, vilidation data 1.1432\n",
      "step 700, the mean error of the training data 0.733637, vilidation data 1.08075\n",
      "step 800, the mean error of the training data 0.659528, vilidation data 1.03587\n",
      "step 900, the mean error of the training data 0.60222, vilidation data 1.00266\n",
      "step 1000, the mean error of the training data 0.557787, vilidation data 0.978714\n",
      "step 1100, the mean error of the training data 0.522908, vilidation data 0.960706\n",
      "step 1200, the mean error of the training data 0.494782, vilidation data 0.946498\n",
      "step 1300, the mean error of the training data 0.471484, vilidation data 0.935005\n",
      "step 1400, the mean error of the training data 0.451685, vilidation data 0.925586\n",
      "step 1500, the mean error of the training data 0.434483, vilidation data 0.917812\n",
      "step 1600, the mean error of the training data 0.419285, vilidation data 0.911384\n",
      "step 1700, the mean error of the training data 0.405697, vilidation data 0.906063\n",
      "step 1800, the mean error of the training data 0.393421, vilidation data 0.901609\n",
      "step 1900, the mean error of the training data 0.382202, vilidation data 0.897765\n",
      "step 2000, the mean error of the training data 0.371841, vilidation data 0.8943\n",
      "step 2100, the mean error of the training data 0.362202, vilidation data 0.891066\n",
      "step 2200, the mean error of the training data 0.353179, vilidation data 0.888017\n",
      "step 2300, the mean error of the training data 0.34466, vilidation data 0.885107\n",
      "step 2400, the mean error of the training data 0.336558, vilidation data 0.882198\n",
      "step 2500, the mean error of the training data 0.328839, vilidation data 0.879125\n",
      "step 2600, the mean error of the training data 0.321493, vilidation data 0.875821\n",
      "step 2700, the mean error of the training data 0.314502, vilidation data 0.872295\n",
      "step 2800, the mean error of the training data 0.307842, vilidation data 0.868595\n",
      "step 2900, the mean error of the training data 0.301494, vilidation data 0.864809\n",
      "step 3000, the mean error of the training data 0.295445, vilidation data 0.861062\n",
      "step 3100, the mean error of the training data 0.28969, vilidation data 0.857499\n",
      "step 3200, the mean error of the training data 0.284225, vilidation data 0.854253\n",
      "step 3300, the mean error of the training data 0.279036, vilidation data 0.851415\n",
      "step 3400, the mean error of the training data 0.274106, vilidation data 0.849008\n",
      "step 3500, the mean error of the training data 0.269407, vilidation data 0.846991\n",
      "step 3600, the mean error of the training data 0.264916, vilidation data 0.845275\n",
      "step 3700, the mean error of the training data 0.260607, vilidation data 0.843758\n",
      "step 3800, the mean error of the training data 0.256458, vilidation data 0.842349\n",
      "step 3900, the mean error of the training data 0.252449, vilidation data 0.840992\n",
      "step 4000, the mean error of the training data 0.248578, vilidation data 0.83968\n",
      "step 4100, the mean error of the training data 0.244861, vilidation data 0.838447\n",
      "step 4200, the mean error of the training data 0.241325, vilidation data 0.837349\n",
      "step 4300, the mean error of the training data 0.237977, vilidation data 0.836434\n",
      "step 4400, the mean error of the training data 0.234813, vilidation data 0.83573\n",
      "step 4500, the mean error of the training data 0.231817, vilidation data 0.835243\n",
      "step 4600, the mean error of the training data 0.228972, vilidation data 0.834966\n",
      "step 4700, the mean error of the training data 0.226255, vilidation data 0.834895\n",
      "step 4800, the mean error of the training data 0.223645, vilidation data 0.835026\n",
      "step 4900, the mean error of the training data 0.221113, vilidation data 0.835349\n",
      "step 5000, the mean error of the training data 0.218631, vilidation data 0.835833\n",
      "step 5100, the mean error of the training data 0.216172, vilidation data 0.836434\n",
      "step 5200, the mean error of the training data 0.213724, vilidation data 0.837129\n",
      "step 5300, the mean error of the training data 0.211415, vilidation data 0.838686\n",
      "step 5400, the mean error of the training data 0.208945, vilidation data 0.838893\n",
      "step 5500, the mean error of the training data 0.20663, vilidation data 0.840077\n",
      "step 5600, the mean error of the training data 0.204365, vilidation data 0.841596\n",
      "step 5700, the mean error of the training data 0.202128, vilidation data 0.843504\n",
      "step 5800, the mean error of the training data 0.199955, vilidation data 0.845758\n",
      "step 5900, the mean error of the training data 0.197883, vilidation data 0.848184\n",
      "step 6000, the mean error of the training data 0.195989, vilidation data 0.850433\n",
      "step 6100, the mean error of the training data 0.194, vilidation data 0.8537\n",
      "step 6200, the mean error of the training data 0.192197, vilidation data 0.856726\n",
      "step 6300, the mean error of the training data 0.190515, vilidation data 0.859655\n",
      "step 6400, the mean error of the training data 0.188926, vilidation data 0.862503\n",
      "step 6500, the mean error of the training data 0.187403, vilidation data 0.865422\n",
      "step 6600, the mean error of the training data 0.185971, vilidation data 0.867856\n",
      "step 6700, the mean error of the training data 0.184596, vilidation data 0.87031\n",
      "step 6800, the mean error of the training data 0.183277, vilidation data 0.872702\n",
      "step 6900, the mean error of the training data 0.182017, vilidation data 0.874758\n",
      "step 7000, the mean error of the training data 0.180771, vilidation data 0.876851\n",
      "step 7100, the mean error of the training data 0.179566, vilidation data 0.878856\n",
      "step 7200, the mean error of the training data 0.178373, vilidation data 0.880809\n",
      "step 7300, the mean error of the training data 0.177215, vilidation data 0.882726\n",
      "step 7400, the mean error of the training data 0.176064, vilidation data 0.884692\n",
      "step 7500, the mean error of the training data 0.174932, vilidation data 0.886823\n",
      "step 7600, the mean error of the training data 0.173815, vilidation data 0.889062\n",
      "step 7700, the mean error of the training data 0.172719, vilidation data 0.89178\n",
      "step 7800, the mean error of the training data 0.171636, vilidation data 0.894466\n",
      "step 7900, the mean error of the training data 0.170582, vilidation data 0.897693\n",
      "step 8000, the mean error of the training data 0.169547, vilidation data 0.901162\n",
      "step 8100, the mean error of the training data 0.168552, vilidation data 0.90463\n",
      "step 8200, the mean error of the training data 0.167606, vilidation data 0.908022\n",
      "step 8300, the mean error of the training data 0.166702, vilidation data 0.911397\n",
      "step 8400, the mean error of the training data 0.165835, vilidation data 0.91477\n",
      "step 8500, the mean error of the training data 0.165011, vilidation data 0.918146\n",
      "step 8600, the mean error of the training data 0.164219, vilidation data 0.921413\n",
      "step 8700, the mean error of the training data 0.163437, vilidation data 0.92479\n",
      "step 8800, the mean error of the training data 0.162698, vilidation data 0.92808\n",
      "step 8900, the mean error of the training data 0.161964, vilidation data 0.931423\n",
      "step 9000, the mean error of the training data 0.161234, vilidation data 0.934796\n",
      "step 9100, the mean error of the training data 0.160687, vilidation data 0.938081\n",
      "step 9200, the mean error of the training data 0.159799, vilidation data 0.94045\n",
      "step 9300, the mean error of the training data 0.159101, vilidation data 0.942556\n",
      "step 9400, the mean error of the training data 0.158381, vilidation data 0.944595\n",
      "step 9500, the mean error of the training data 0.157899, vilidation data 0.946603\n",
      "step 9600, the mean error of the training data 0.157047, vilidation data 0.949975\n",
      "step 9700, the mean error of the training data 0.156408, vilidation data 0.952962\n",
      "step 9800, the mean error of the training data 0.155793, vilidation data 0.956102\n",
      "step 9900, the mean error of the training data 0.155378, vilidation data 0.959596\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "train_error = []\n",
    "valid_error = []\n",
    "training_epochs = 10000\n",
    "best_valid_error = numpy.inf\n",
    "for i in range(training_epochs):\n",
    "    if i%100 == 0:\n",
    "        train_err = cost_function.eval(feed_dict={x:train_set1, y_:train_dtws})\n",
    "        train_error.append(train_err)\n",
    "        valid_err = cost_function.eval(feed_dict={x:valid_set1, y_:valid_dtws})\n",
    "        valid_error.append(valid_err)\n",
    "        print(\"step %d, the mean error of the training data %g, vilidation data %g\"%(i, train_error[-1], valid_error[-1]))\n",
    "        #print h_conv1_flat.eval(feed_dict={x:test_set1})\n",
    "        if valid_error[-1] < best_valid_error * 0.995:\n",
    "            best_valid_error = valid_error[-1]\n",
    "            #saver = tf.train.Saver({\"W_0\": W_conv1, \"b_0\":b_conv1})\n",
    "            W_best = sess.run(W_conv1)\n",
    "            b_best = sess.run(b_conv1)\n",
    "             \n",
    "    train_step.run(feed_dict={x:train_set1, y_:train_dtws})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJkiRJkiRJkiRJkiTpwPX/AXEd6kP8dbyBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabd0132190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training error and validation error\n",
    "Xaxis = range(training_epochs/100)\n",
    "for i,x in enumerate(Xaxis):\n",
    "    Xaxis[i] = x * 100\n",
    "plt.plot(Xaxis, train_error, 'r',label='train error')\n",
    "plt.plot(Xaxis, valid_error, 'g',label='validation error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 1, 1, 100)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the weight matrix from the trained model\n",
    "W_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the bias vector from the trained model\n",
    "b_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rescale the test dataset\n",
    "test_set_rescale = test_set/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape the W matrix to [23,10]\n",
    "W_prime = numpy.reshape(W_best,[23, numFeatureMaps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output the hidden features\n",
    "test_hidden_features = tf.nn.sigmoid(numpy.matmul(test_set,W_prime)+b_best)\n",
    "test_features = sess.run(test_hidden_features)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for one time series in test dataset, calculate its distance with 1000 time series in test dataset\n",
    "euclidean_dists = []\n",
    "dtw_dists = []\n",
    "for i in range(1000):\n",
    "    dtw_dists.append((i,dtw(test_set_rescale[i], test_set_rescale[-2])))\n",
    "    euclidean_dists.append((i, euclideanDist(test_features[i], test_features[-2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort the result\n",
    "euclidean_dists_sorted = sorted(euclidean_dists, key=(lambda x: x[1]))\n",
    "dtw_dists_sorted = sorted(dtw_dists, key=(lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(812, 1.0000000004536678),\n",
       " (758, 1.4142075565193533),\n",
       " (820, 1.414208079809431),\n",
       " (361, 1.4142135597488719),\n",
       " (308, 1.4142149732054206),\n",
       " (788, 1.7318595692863328),\n",
       " (309, 1.7320463165532396),\n",
       " (425, 1.732050805426201),\n",
       " (99, 1.7320508054262083),\n",
       " (272, 1.7320508054262083),\n",
       " (513, 1.7320508054262083),\n",
       " (559, 1.7320508054262083),\n",
       " (686, 1.7320508054262083),\n",
       " (691, 1.7320508054262083),\n",
       " (768, 1.7320508054262083),\n",
       " (790, 1.7320508054262083),\n",
       " (894, 1.7320508054262083),\n",
       " (895, 1.7320508054262083),\n",
       " (535, 1.9997139014817822),\n",
       " (418, 1.9999961232458123)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dists_sorted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(812, 1.2431372549019608),\n",
       " (58, 1.4235294117647057),\n",
       " (852, 1.4352941176470588),\n",
       " (308, 1.447058823529411),\n",
       " (884, 1.4941176470588238),\n",
       " (513, 1.4980392156862745),\n",
       " (559, 1.5333333333333332),\n",
       " (382, 1.541176470588235),\n",
       " (361, 1.5843137254901958),\n",
       " (662, 1.5999999999999999),\n",
       " (788, 1.6392156862745095),\n",
       " (580, 1.658823529411765),\n",
       " (590, 1.7019607843137252),\n",
       " (813, 1.7098039215686267),\n",
       " (235, 1.7450980392156863),\n",
       " (99, 1.7568627450980385),\n",
       " (77, 1.7568627450980394),\n",
       " (591, 1.772549019607843),\n",
       " (435, 1.7764705882352938),\n",
       " (419, 1.788235294117647)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_dists_sorted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# take out 100 neighbors using both euclidean distance and dtw distance. \n",
    "# See the number of the overlap neighbors between them\n",
    "euclid_set = set()\n",
    "dtw_set = set()\n",
    "for i in range(100):\n",
    "    euclid_set.add(euclidean_dists_sorted[i][0])\n",
    "    dtw_set.add(dtw_dists_sorted[i][0])\n",
    "count = 0\n",
    "for x in euclid_set:\n",
    "    if x in dtw_set:\n",
    "        count += 1\n",
    "print count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
