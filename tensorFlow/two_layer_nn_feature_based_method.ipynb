{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contained the feature-based similarity search method using two-layer neural network\n",
    "\n",
    "Created by Zexi Chen(zchen22)\n",
    "Date: Oct 2, 2016\n",
    "\"\"\"\n",
    "\n",
    "import numpy\n",
    "import six.moves.cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from ConvLayer import ConvLayer\n",
    "from helper import loadData, dtw, euclideanDist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data and rescale to 0-1\n",
    "# samples* is a dataset with 10000 time series sampled from original images(2001 image and 2006 image) randomly\n",
    "train_set = loadData('../theano/data/samples1')\n",
    "valid_set = loadData('../theano/data/samples2')\n",
    "test_set = loadData('../theano/data/samples3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePairs(dataset, numInstance):\n",
    "    # pick numInstance pairs of time series at random from the training set    \n",
    "    sampleIndices = numpy.random.choice(dataset.shape[0], 2 * numInstance)\n",
    "    data_set_samples = numpy.zeros((2 * numInstance, dataset.shape[1]),dtype=numpy.float32)\n",
    "    for i in range(numInstance * 2):\n",
    "        data_set_samples[i] = dataset[sampleIndices[i]]\n",
    "    \n",
    "    data_set_reshape = numpy.reshape(data_set_samples, (data_set_samples.shape[0]/2, data_set_samples.shape[1]*2))\n",
    "    data_set1 = data_set_reshape/255.0\n",
    "    data_dtws = numpy.zeros((data_set1.shape[0],1), dtype=numpy.float32)\n",
    "    for i in range(data_set1.shape[0]):\n",
    "        data_dtws[i,0] = dtw(data_set1[i,0:23], data_set1[i,23:])**2\n",
    "    \n",
    "    return data_set1, data_dtws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shuffle, make pairs of time series,and calculate pair-wise dtw \n",
    "valid_set1, valid_dtws = makePairs(valid_set, valid_set.shape[0])\n",
    "test_set1, test_dtws = makePairs(test_set, test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the neural network model\n",
    "# start the tensorflow interaction interface\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hiddens = [200,100,50]\n",
    "learning_rate = [1e-2]\n",
    "training_iter = 10000\n",
    "\n",
    "# create two variable placehold, x for the training features, \n",
    "# y for the labels(in this model it is the dtw distance between two time series)\n",
    "x = tf.placeholder(tf.float32, shape=[None, train_set.shape[1]*2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "layer1 = ConvLayer(\n",
    "    None,\n",
    "    None,\n",
    "    input = x,\n",
    "    activation = tf.nn.sigmoid,\n",
    "    n_visible = train_set.shape[1]*2,\n",
    "    n_hidden =  n_hiddens[0]\n",
    ")\n",
    "\n",
    "layer2 = ConvLayer(\n",
    "    None,\n",
    "    None,\n",
    "    input = layer1.output,\n",
    "    activation = tf.nn.sigmoid,\n",
    "    n_visible = n_hiddens[0]*2,\n",
    "    n_hidden = n_hiddens[1]\n",
    ")\n",
    "\n",
    "layer3 = ConvLayer(\n",
    "    None,\n",
    "    None,\n",
    "    input = layer2.output,\n",
    "    activation = tf.nn.sigmoid,\n",
    "    n_visible = n_hiddens[1]*2,\n",
    "    n_hidden = n_hiddens[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the cost and minimize it\n",
    "cost = layer3.cost_function(y)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate[0]).minimize(cost)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, mean training error 1443.69, validation error 1577.79\n",
      "step 100, mean training error 751.737, validation error 707.074\n",
      "step 200, mean training error 635.389, validation error 703.929\n",
      "step 300, mean training error 653.056, validation error 698.808\n",
      "step 400, mean training error 644.607, validation error 700.041\n",
      "step 500, mean training error 663.364, validation error 696.917\n",
      "step 600, mean training error 645.294, validation error 694.994\n",
      "step 700, mean training error 665.395, validation error 696.426\n",
      "step 800, mean training error 646.279, validation error 698.044\n",
      "step 900, mean training error 654.838, validation error 694.287\n",
      "step 1000, mean training error 650.546, validation error 692.492\n",
      "step 1100, mean training error 658.74, validation error 692.823\n",
      "step 1200, mean training error 661.229, validation error 694.555\n",
      "step 1300, mean training error 641.059, validation error 694.165\n",
      "step 1400, mean training error 640.232, validation error 691.868\n",
      "step 1500, mean training error 649.274, validation error 691.416\n",
      "step 1600, mean training error 645.268, validation error 691.564\n",
      "step 1700, mean training error 630.262, validation error 691.28\n",
      "step 1800, mean training error 654.269, validation error 691.333\n",
      "step 1900, mean training error 633.237, validation error 691.032\n",
      "step 2000, mean training error 646.772, validation error 691.117\n",
      "step 2100, mean training error 662.709, validation error 691.781\n",
      "step 2200, mean training error 668.524, validation error 691.085\n",
      "step 2300, mean training error 659.583, validation error 694.039\n",
      "step 2400, mean training error 648.086, validation error 690.774\n",
      "step 2500, mean training error 629.115, validation error 691.445\n",
      "step 2600, mean training error 629.187, validation error 691.902\n",
      "step 2700, mean training error 641.576, validation error 690.41\n",
      "step 2800, mean training error 642.224, validation error 691.918\n",
      "step 2900, mean training error 644.721, validation error 691.024\n",
      "step 3000, mean training error 638.305, validation error 697.616\n",
      "step 3100, mean training error 651.269, validation error 691.107\n",
      "step 3200, mean training error 638.158, validation error 690.644\n",
      "step 3300, mean training error 623.262, validation error 690.274\n",
      "step 3400, mean training error 643.24, validation error 690.128\n",
      "step 3500, mean training error 641.884, validation error 690.452\n",
      "step 3600, mean training error 635.982, validation error 691.511\n",
      "step 3700, mean training error 640.438, validation error 690.857\n",
      "step 3800, mean training error 647.402, validation error 691.306\n",
      "step 3900, mean training error 646.315, validation error 689.99\n",
      "step 4000, mean training error 654.159, validation error 692.655\n",
      "step 4100, mean training error 618.872, validation error 691.323\n",
      "step 4200, mean training error 639.883, validation error 690.008\n",
      "step 4300, mean training error 650.214, validation error 690.619\n",
      "step 4400, mean training error 644.476, validation error 690.292\n",
      "step 4500, mean training error 651.736, validation error 692.691\n",
      "step 4600, mean training error 653.43, validation error 690.633\n",
      "step 4700, mean training error 620.483, validation error 689.411\n",
      "step 4800, mean training error 641.18, validation error 690.458\n",
      "step 4900, mean training error 661.702, validation error 690.127\n",
      "step 5000, mean training error 642.068, validation error 689.662\n",
      "step 5100, mean training error 630.666, validation error 690.141\n",
      "step 5200, mean training error 649.471, validation error 690.27\n",
      "step 5300, mean training error 649.061, validation error 689.906\n",
      "step 5400, mean training error 637.98, validation error 690.65\n",
      "step 5500, mean training error 649.051, validation error 689.613\n",
      "step 5600, mean training error 641.12, validation error 689.684\n",
      "step 5700, mean training error 647.598, validation error 689.552\n",
      "step 5800, mean training error 643.1, validation error 690.987\n",
      "step 5900, mean training error 651.287, validation error 690.424\n",
      "step 6000, mean training error 657.97, validation error 691.325\n",
      "step 6100, mean training error 665.067, validation error 689.239\n",
      "step 6200, mean training error 631.074, validation error 690.919\n",
      "step 6300, mean training error 659.738, validation error 690.424\n",
      "step 6400, mean training error 645.568, validation error 689.734\n",
      "step 6500, mean training error 615.858, validation error 689.914\n",
      "step 6600, mean training error 638.704, validation error 689.773\n",
      "step 6700, mean training error 650.655, validation error 689.796\n",
      "step 6800, mean training error 638.618, validation error 689.457\n",
      "step 6900, mean training error 657.054, validation error 689.984\n",
      "step 7000, mean training error 630.151, validation error 689.346\n",
      "step 7100, mean training error 657.134, validation error 690.363\n",
      "step 7200, mean training error 633.348, validation error 690.602\n",
      "step 7300, mean training error 626.692, validation error 692.56\n",
      "step 7400, mean training error 654.34, validation error 694.317\n",
      "step 7500, mean training error 617.168, validation error 688.897\n",
      "step 7600, mean training error 634.563, validation error 689.226\n",
      "step 7700, mean training error 641.109, validation error 689.969\n",
      "step 7800, mean training error 636.782, validation error 689.539\n",
      "step 7900, mean training error 647.064, validation error 689.201\n",
      "step 8000, mean training error 640.337, validation error 689.315\n",
      "step 8100, mean training error 647.377, validation error 689.809\n",
      "step 8200, mean training error 638.186, validation error 691.806\n",
      "step 8300, mean training error 649.86, validation error 689.47\n",
      "step 8400, mean training error 660.539, validation error 689.755\n",
      "step 8500, mean training error 644.921, validation error 689.244\n",
      "step 8600, mean training error 643.499, validation error 688.676\n",
      "step 8700, mean training error 640.885, validation error 689.777\n",
      "step 8800, mean training error 633.995, validation error 691.801\n",
      "step 8900, mean training error 657.955, validation error 689.098\n",
      "step 9000, mean training error 632.498, validation error 689.68\n",
      "step 9100, mean training error 643.128, validation error 688.753\n",
      "step 9200, mean training error 646.201, validation error 691.72\n",
      "step 9300, mean training error 649.031, validation error 688.681\n",
      "step 9400, mean training error 638.172, validation error 690.615\n",
      "step 9500, mean training error 633.038, validation error 687.606\n",
      "step 9600, mean training error 647.682, validation error 690.985\n",
      "step 9700, mean training error 650.543, validation error 688.155\n",
      "step 9800, mean training error 650.514, validation error 690.336\n",
      "step 9900, mean training error 619.801, validation error 687.979\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "train_error = []\n",
    "valid_error = []\n",
    "best_valid_error = numpy.inf\n",
    "numInstance = 1000\n",
    "train_iter_error = []\n",
    "for i in range(training_iter):\n",
    "    sample_train_set, sample_train_dtws = makePairs(train_set, numInstance)\n",
    "    space_holder, train_err = sess.run([train_step, cost], feed_dict={x:sample_train_set, y:sample_train_dtws})\n",
    "    train_iter_error.append(train_err)\n",
    "    if i%100 == 0:\n",
    "        train_error.append(numpy.mean(train_iter_error))\n",
    "        train_iter_error = []\n",
    "        valid_err = sess.run([cost],feed_dict={x:valid_set1, y:valid_dtws})\n",
    "        valid_error.append(valid_err)\n",
    "        print(\"step %d, mean training error %g, validation error %g\"%(i, train_error[-1], valid_error[-1][0]))\n",
    "        if valid_error[-1][0] < best_valid_error * 0.995:\n",
    "            W_1 = sess.run(layer1.W)\n",
    "            b_1 = sess.run(layer1.b)\n",
    "            W_2 = sess.run(layer2.W)\n",
    "            b_2 = sess.run(layer2.b)\n",
    "            W_3 = sess.run(layer3.W)\n",
    "            b_3 = sess.run(layer3.b)\n",
    "            best_valid_error = valid_error[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8XHWd//HXXHNr2ia9prTQC61QqLS0Aj8UiCJuBZfi\nZQHRrgvu+liLsrAqCKhFVBQUEdgfuCyCuAIKLIsCihQhyIq0QC3b0pZeaGmTtmnapmnuczmf/eM7\nSSaZpGnTpOfQeT8fj3lk5syZM99z5pzz/l7OTEBERERERERERERERERERERERERERCSQ7gNqgZU9\npn8ZWAOsAm7Omn4tsB5YC3wka/rczDLWA7cPVWFFROTwOAOYQ/dw+CCwBIhlHo/J/J0JrMhMnwxs\nAEKZ55YBp2Tu/w6YP2QlFhGRw2Iy3cPhEeBDvcx3LXBN1uNngNOAClwro8PFwE8Ht4giIjKYwgN4\nzXTgTOAVoAqYl5k+AajOmq8aOKqX6TWZ6SIiElDRAb6mDNcqeB+uJTF1MAslIiL+Gkg4VAOPZ+6/\nCnjAaFyLYFLWfBMz89Zk7mdPr+ltwdOmTbONGzcOoEgiInltI3DsYC5wIN1KT9A15jADiAO7gN/i\nxhPiwBRc99MyYAewDzgVN0C9MLOMHBs3bsTMdDNj8eLFvpchKDdtC20LbYv934BpAziX71d/LYeH\ngbOAUcBW4Fu4y1vvww1SJ4C/z8y7GtfFtBpIAYsAyzy3CPg5UIS7WumZwVoBEREZfP2Fw6f7mL6w\nj+k3ZW49vQ7MOtBCiYiIvwbSrSSHQWVlpd9FCAxtiy7aFl20LYZWqP9ZDivL9J+JiMgBCoVCMMjn\nc7UcREQkh8JBRERyKBxERCSHwkFERHIoHEREJIfCQUREcigcREQkh8JBRERyKBxERCSHwkFERHIo\nHEREJIfCQUREcigcREQkh8JBRERyKBxERCSHwkFERHIoHEREJIfCQUREcigcREQkh8JBRERyKBxE\nRCSHwkFERHIoHEREJIfCQUREcigcREQkh8JBRERyKBxERCSHwkFERHIoHEREJIfCQUREcigcREQk\nh8JBRERyKBxERCSHwkFERHL0Fw73AbXAyl6e+wrgAeVZ064F1gNrgY9kTZ+bWcZ64PaBFlZERA6P\n/sLhfmB+L9MnAecA72RNmwlclPk7H7gLCGWeuxv4PDA9c+ttmSIiEhD9hcNLQH0v038MXN1j2gLg\nYSAJbAY2AKcCFUApsCwz3y+ACwZWXBERORwGMuawAKgG/rfH9AmZ6R2qgaN6mV6Tmd4rMxtAkURE\nZDBFD3L+YuA6XJdSh1Af8w7I4hsWEw65zKqsrKSysnIwFy8i8q5XVVVFVVXVkL7HgZzYJwNPArMy\nt+eAlsxzE3EtgVOBSzPTfpD5+wywGDcu8QJwfGb6p4GzgH/u5b2sNdlKYbTwoFZCRCSfhUIhGOSK\n+sF2K60ExgFTMrdq4GTcFU2/BS4G4pnnpuPGGXYA+3ABEgIWAk/09QYpL3WQRRIRkcHWXzg8DLwM\nzAC20tU66JA9QLAaeCTz9/fAoqznFwH34i5l3YBrVfRK4SAi4r9BbYYMAtvZtJMxJWP8LoeIyLtG\nELqVhpxaDiIi/gtcOCS9pN9FEBHJe4ELB7UcRET8F7hwSKbVchAR8VvgwkEtBxER/ykcREQkR+DC\nQQPSIiL+C1w4qOUgIuK/wIWDBqRFRPwXuHBQy0FExH8KBxERyRG4cNCAtIiI/wIXDmo5iIj4L3Dh\noAFpERH/BS4c1HIQEfGfwkFERHIELhyS6YTfRRARyXuBC4dUSuEgIuK3wIVDMtHmdxFERPJe4MIh\nlWr3uwgiInkvcOGgloOIiP8CFw4acxAR8V/wwiGpbiUREb8FLhySCgcREd8FLhzUrSQi4r/AhUNS\nVyuJiPgucOGQ0jekRUR8F7xwSOlXWUVE/Ba4cEhqzEFExHeBCwd1K4mI+C9w4aB/9iMi4r/AhUNK\n4SAi4juFg4iI5AhcOCQ9hYOIiN8CFw6ptP5NqIiI3/oLh/uAWmBl1rQfAmuAN4DHgRFZz10LrAfW\nAh/Jmj43s4z1wO37e0O1HERE/NdfONwPzO8x7VngBOAkYB0uEABmAhdl/s4H7gJCmefuBj4PTM/c\nei6zU8pTy0FExG/9hcNLQH2PaUsAL3N/KTAxc38B8DCQBDYDG4BTgQqgFFiWme8XwAV9vWHSFA4i\nIn471DGHy4DfZe5PAKqznqsGjuplek1meq/UchAR8d+hhMP1QAJ4aJDKAkDK0oO5OBERGYDoAF/3\nD8C5wNlZ02qASVmPJ+JaDDV0dT11TK/pa8Gbn6/nBrsBgMrKSiorKwdYRBGRI1NVVRVVVVVD+h6h\n/mdhMvAkMCvzeD5wK3AWsCtrvpm4VsQpuG6j54BjAcONTVyBG3d4GrgDeKaX97I53xzL8htrD3Y9\nRETyVigUggM7nx+w/loOD+NCYDSwFViMuzopjhuYBvgLsAhYDTyS+ZvKTLPMPIuAnwNFuDGK3oIB\ngCTqVhIR8dugJs0gsOO+MZI13+l5gZSIiPRlKFoOwfuGdOdVsiIi4pfAhUNSVyuJiPgucOGgloOI\niP8CFw7JkMJBRMRvgQsHtRxERPwXwHCw/mcSEZEhFbhwULeSiIj/AhcOqZBaDiIifgtcOCTDhpkC\nQkTET4ELh5CBZ+paEhHxU+DCIeaF9K9CRUR8FrhwiJr+4Y+IiN8CFw4xL6RwEBHxWeDCIepBMq1u\nJRERPwUyHNRyEBHxV+DCIZZGA9IiIj4LXDhEPVPLQUTEZ4ELh1hK4SAi4rfAhUPUg2Qq4XcxRETy\nWiDDIZVq97sYIiJ5LXDhELMQyfZWv4shIpLXAhcOUQuRSrT5XQwRkbwWuHCIWVjhICLis8CFQ5QQ\nyYS6lURE/BTAcAiTSmpAWkTET4ELh5hFNCAtIuKzwIVDlLAuZRUR8VngwiEWipDUgLSIiK8CFw4a\ncxAR8V/wwiEUIZXUz2eIiPgpcOEQI0IyqW4lERE/BS4couEIKf3wnoiIrwIXDrFQhKSuVhIR8VXg\nwiEaiqrlICLis8CFQyyscBAR8VvgwiEajuqf/YiI+Ky/cLgPqAVWZk0rB5YA64BngZFZz10LrAfW\nAh/Jmj43s4z1wO37e8NoOEoqnTyQsouIyBDpLxzuB+b3mPZ1XDjMAP6YeQwwE7go83c+cBcQyjx3\nN/B5YHrm1nOZnWLhmAakRUR81l84vATU95h2PvBA5v4DwAWZ+wuAh4EksBnYAJwKVAClwLLMfL/I\nek0O13JIHVjpRURkSAxkzGEcrquJzN9xmfsTgOqs+aqBo3qZXpOZ3qtYJEYyrTEHERE/HeqAtGVu\ngyYaiZHy1HIQEfFTdACvqQXGAztwXUY7M9NrgElZ803EtRhqMvezp9f0tfDnXtpCQ6idG1I3UFlZ\nSWVl5QCKKCJy5KqqqqKqqmpI3yPU/yxMBp4EZmUe3wLsBm7GDUaPzPydCTwEnILrNnoOOBbXslgK\nXIEbd3gauAN4ppf3sju/fR5r0jv4/99+bWBrJCKSZ0KhEBzY+fyA9ddyeBg4CxgNbAW+BfwAeAR3\n9dFm4MLMvKsz01cDKWARXV1Oi4CfA0XA7+g9GFyBIjFSCXUriYj4qb9w+HQf0z/cx/SbMreeXqer\n5bFfsUicpCkcRET8FLxvSEc1IC0i4rcAhkNc4SAi4rPAhUMsWqBuJRERnwUuHKLROClL+10MEZG8\nFrhwiMUKSSocRER8FbhwUMtBRMR/wQuHWIHCQUTEZ4ELh1isgCQKBxERPwUuHKLxQlJ4fhdDRCSv\nBS4c1HIQEfFf4MLBtRwG9VfARUTkIAUvHGIFJNWtJCLiq8CFQ6ygSGMOIiI+C1w4RONFpELqVhIR\n8VPgwiEWLyIZUstBRMRPgQuHaEGhWg4iIj4LXDjE4kUkwwoHERE/BS4cooXFajmIiPgseOEQLyQ1\nqP8mW0REDlbgwiFWWEIy4ncpRETyW+DCIRorIBUG0voJDRERvwQuHGKRGMkIWHu730UREclbgQuH\ncChMyMBLKBxERPwSuHAAiHqQam/xuxgiInkrkOEQ80Ik21v9LoaISN4KZDhEDVJtajmIiPglkOEQ\n80IkE2o5iIj4JZDhELUQqfY2v4shIpK3ghkOhNVyEBHxUSDDIWYhUgm1HERE/BLIcIhamJSuVhIR\n8U0gwyFGmGRSLQcREb8EMhyihNWtJCLio8CGQzKpn88QEfFLIMMhppaDiIivAhkO0VCEVCrhdzFE\nRPLWoYTDtcCbwErgIaAAKAeWAOuAZ4GRPeZfD6wFPrK/BceIaEBaRMRHAw2HycA/AScDs4AIcDHw\ndVw4zAD+mHkMMBO4KPN3PnDX/t47GoqQSqrlICLil4GGwz4gCRQD0czfbcD5wAOZeR4ALsjcXwA8\nnHnNZmADcEpfC4+FIiRTajmIiPhloOGwB7gV2IILhb24FsM4oDYzT23mMcAEoDrr9dXAUX0tPBqK\nkkolB1g0ERE5VNEBvm4acCWue6kBeBT4bI95LHPrS6/P3XDDDax/qYEHC5Yy/OQqKisrB1hEEZEj\nU1VVFVVVVUP6HqEBvu4i4BzgHzOPFwKnAR8CPgjsACqAF4Dj6Bp7+EHm7zPAYmBpj+WamXHhN4/j\nk4Unc9H1Dw2weCIi+SMUCsHAz+e9Gmi30lpcGBThCvRhYDXwJPC5zDyfA57I3P8tbsA6DkwBpgPL\n+lp4NBwlldaAtIiIXwbarfQG8AvgNcADlgP3AKXAI8DncQPPF2bmX52ZvhpIAYvYT5dTLBwlqe85\niIj4ZqDhAHBL5pZtD64V0ZubMrf+CxWOkUpoQFpExC/B/IZ0OEpS3UoiIr4JZDjEIjFSabUcRET8\nEshwiEaiCgcRER8FMhxikThJL+V3MURE8lYgwyGqbiUREV8FNhySnsJBRMQvgQyHWMlwUi1NfhdD\nRCRvBTIcouWjSTXs9bsYIiJ5K5DhECsfTbK1CZLqWhIR8UMgwyEaLSBVWgJbtvhdFBGRvBTMcAhH\nSY4shU2b/C6KiEheCmQ4xCIxUsOHKRxERHwSyHCIhqMkS0sUDiIiPglkOMTCMVLDihUOIiI+CWQ4\nRMNRUiVFCgcREZ8EMhxikRgrE9U8El7D5r2bMdvfv6IWEZHBNqj/c3QQmJmxp3UPdy+7i1fvWczS\nOWMw4ILjLuCiEy7izGPOJBKOdMyMZ17nYxGRfDQU/0M6kOHQ6bjjsMce4+0JRTy2+jF+9eav2NG0\ng3El46hrqWNXyy4ioQgnjT+JUyacwrwJ85g+ajpTRk5hbMlYAPa172NH0w62NW6jprGG6n3V7Gze\nyayxs6icXMmUsik+rWqwvb7tdd6ofYNPzfwUwwuG+10cEdmP/AuHj34ULr8cPvaxzkkb9mygoa2B\nsSVjGV08mqSXZPn25bxa8yqvb3+djfUb2VS/iZZkC+DGL8YPG09FaQUTh09kYulEyovKWVG7gqrN\nVRRECpg9fjbHjDiGY0Yew9iSsaS9NIl0grZUG9ubtrN131a2NGyhOdFMQbSAgkgBw+LDmF4+nfeM\nfg8zRs2grLCMwmghBdECIqEInnmkLY2ZEQ1HiUVixMIxt5KZf58dItQ5PRaJdbaEDKM12Upzspnm\nRDOeeZTESxgWH0Y4FGbVzlW8vu11VtSuoLywnNMmnsapE0/lmBHHkPSSNCWaaEm20JZq67wNiw+j\nYlgFwwuGEwqFSKaT7Gjawc7mnRTFihhRMILSglKWbFzCT5b+hC0NW5g9fjYvvfMSC9+7kC+d8iWm\nlk0dUCvNM4+9bXtpSjRRHCumJFZCYbQQw2hPtdOWaiMeiVMSL+l8TTKdZN3udbxZ9ybRcJRxJeMY\nN2wcY0vGUhov7TgY9quuuY41u9awpWELE0onMK1sGhOHTwx0S7Nj/++5fikvRWN7IyMKRxAOBbI3\nGIBEOsGWhi28Xf82m/duZkvDFrY0bKGupY6zp5zNJbMuYULphCF5bzNjV8sudrfuZvLIyRRGCw95\nmfWt9dQ21x7U8syM6n3VjCgccdgqVvkXDosWwfHHw5e/fNALamxvJBwKdzvh9PJmnSegd/a+wzsN\n77CzeSexSIx4OE48EqeitIJJwydx9IijGRYfRnu6nUQ6QUNbA+t2r+Ot3W+xbvc69rXvoz3tTnRp\nL00kHCEcChMiRMpLkfSSJDM/Qx4KhQgRwjOvc3rSS3bOHwqFKIoWURIvoSRWQjgU7gyKRDrBCWNP\n4OTxJzOnYg67W3bzSs0r/GXrX9jVsotQKERJrISSeAlF0aLOwGpsb2Rb4zYMozhWzN62vYwrGceY\nkjG0pdpoaGtgb9teZo+fzVWnXcXHj/840XCUrQ1buevVu7hvxX3UNdcRCUfcMiMFxCNxCqIFxMIx\nIuEIkZBb55SXIpFOdAZVQ1sDpQWllMRKaE21dq6HYZ3Lak+3Ew6FGVsyluJYMW/Xv83RI47mhDEn\n4JlHbXMtO5t3UttUS9rSjCsZR1lRGe2pdlqSLZ2VgXgkTiwSo7G9kbSlOX708Rw94mi2N21n456N\n7G7dzdiSsYwpHsOYkjEURgupb61nd+tuGtoaiIQjxMKxznUrjBZSFC0iEo7QlmqjNdlKW6qtM/w9\n84iEIp3zhwjRmGiksb2RlmQLJfESyovKKS8qpyBSgGGdARAOhTuDanfLbrY3bWdH0w7aU+0UxYoo\njhUTC8fY176PtlQbJfESEukEk0dOZlrZNAqjhWzdt5WtDVupa6kjFo5RFHOfeUnMVSZK4iXEI3HS\nXrqzvOFQ2L13qHtIhkIh4hG330dCEdrT7Z3rGwlHOverECHq2+qpb62nob2BRDrh9vF0ksZEIxNK\nJzC1bCqTR0zmmJHHcPSIoxlRMIKn1j3F42sfZ96EecwaO4tEOkEinaA93U5jeyONiUaaE81Ew9HO\nbd9RnngkTjQUxcNz295Ldx5vrclW6lrqeLv+beKROOVF5VTvq6ZiWAUzRs2gIFrQWb6OY6soVkRR\n1G3jjsfNiWZ2t+5md+tutjduZ2P9RtJemrElY6lprGFq2VRmjZ1Fcay42z43onAEIwtGEo/EWVW3\niuXblxMiREuyhaOGH8W8CfOoGFbB5r2b2bR3EzuadjBj1AzmVczj5IqTaWhv4OWtL/Py1pfZ3rSd\nWWNnMWf8HI4fczy1TbWs37Oe9XvWUxAp4LjRx3Hc6OOYWzGXc6ad0+2zI6/C4Yc/hO3b4cc/9q9E\n7xJmRtJLEo/E9ztfx0lrdPHog65BmxkpL0VrqtUd1Kn2zrD0zOu8RcNRd5IOxyiJl1BWWJbzXmkv\n7cIwU0M2M5qTzdQ21dKcbObY8mMpjhX3Wo7mRDM7m3eyp3WPOxFmghAg6SVJpBMUx4oZVzIupwbe\nmmyltrmWuuY66lrqaEu1dZ68RxSMwDOv20mro+WV8lKdYVsYLewM/3AojGce7amu7VBaUEppvJTi\nWDHNyWb2tO5hT+se2lPtnRUDoHN7GcaoolGMHzae8cPGUxgtpDXVSkuyhWQ6yfCC4QyLDyMUciec\nt+vfZsOeDSTSCSYNn8SkEZMYWzKWZDrpTpaZAG5ONtOUaCKRThAJRTrLbGakLU3aS3fbPp55JNPJ\nzpN9QbSgc53TlqY54ZZnGGWFZW6bFY6gIFJANBwlEo5QVlhGLBLrcx9qTbby1LqnqN5X7SphkXhn\nS7yjApG2dOd2T6QT3crUsc3DoXC38o0qHsXUsqmMLBwJuJbWpvpNvLX7LZLpZGcL3bDOQGlJttCa\nau28XxIvYVTRKEYVu89iWtk0yovKCYVCtKfaWbNrDStrV3buXx37Z0O7q1i1pdo4fvTxzJ0wl4ph\nFaQtzdpda3lt22vsaNrB5JGTmTJyCuOGjeOtXW/x2rbXWL5jOcMLhnP6xNM5fdLpTCidwKqdq1ix\nYwVrdq1hXMk4po+azvTy6bSn21m7ay1rd62lKFrEdz70nc7tmn/h8Nhj8OCD8N//7V+JREQCbijC\nIbidlwBTpui7DiIiPnh3hIO+5yAiclgFOxzKytzf+vpDW04iAevXH3p5/OJ5sGQJXHwxjBsHN90E\n7e1+l0r8tHevu4kMkWCHQyh04F1Lu3bBuefCW2/lPnfllTB7NqxcefBl8Dz3/k8/DdXVB//6Q/XM\nMzBtGlxzDZxxhnv8yiswa5a7L0Pjz3+GzZv9LkWubdvgq1+FSZNg4cLe51FLu3dNTYde0RTfWI4L\nLjB79NHc6dmSSbMPfcjszDPNZsww27On67lf/9ps2jSzf/s3s2OPNauv3/+yOjz/vNlZZ5mVlJhN\nnGj2gQ+4Ze/bd2CvHwxVVWZjxriy9PTUU269LrvMrKXl8JUpH6xbZzZypNkJJ5g1NfldGmf1arN/\n+iezsjKzK64wW7vW7RtvvdV9vlTKbO5cs+uvN/O8wXnvl182q63Nne55Zr/5jVk6PTjvM5Reesns\nmGPcOaCmZuDL+Y//yN3mAQAc8TWC3LW+6iqzW27pevyb35j98Y/d5/nXfzX7m79xB8aVV5p9+MMu\nMNavNxs92uy119x8l19u9rd/27Uzv/66C5U5c8yuvdbsT38y++tfzc4912zqVLMHHzTbu7frfT7/\nebPPfGZwDrpHHjG78ca+n1+6tO9g6NDYaPbpT5uddJJb16GUvR0Ol2XLzD71KbOVKwe+jHTanRh+\n/nOz737X7Etfcif/vrS1mZ18stmdd5r9/d+bLVw4eCfZg+V5Zs895/bHsWPNFi8227mz6/nrrzdb\ntKj7a/7zP83mzTObPdvsy18+uBN3b+v56qtmhYVmF1+c+9xTT5mB2V137X+5bW1mF15otmvXgZdl\nsCQSZt/4htm4cWa//a3ZTTeZHX989+14oJYtM4vHXaXRr32iD+RlONxxh9kXv+juP/usO0imTjX7\n2MfM1qxxJ/CpU81273bzJJMuKP75n7sO8g7t7Wann2529dVml15qNn682T33uJPHdde5A2rMGLOf\n/MTt0D01N7va5M9+1vsn1N5uduut7r0ffbSrTD3V1rr3qagw+93vcp9fubJrZ+6P57mDc8wYsyef\n7H/+gXjwQXdQXHPN0NQSa2rMXnjB7I03zKqrzVasMPv4x82OOsqF+ec+t//Xv/mmO2A/+Umzp592\n+0AqZfbQQ+7zOvFEF+pf/7o74X/qU30v66qrzBYscNu1qcm9/p57+p7/tttcZeS888w+8Qn3Hs3N\n3efxPLeMO+/M3a9SKbMXX8ytzS5d6lrCxx1ndu+9Zq2tue+9bZtr4XTsZ+3t7lh44QXXQj79dLN/\n+Ae3PfanudmF4OzZZhs3dk3fvt1s0iQXOBMmmL3yStdzyaQ7yf7gB64Ctr/a+K23moVCZj/60f7L\nsT/pdN/vUVNjtmNH7vQtW8xOO82dD7Zv75p+/fWuQpXdw9CfZNJtn/vvd6/91a/6L+9bb7mei69/\n3ex733Ofz/7s22f205+afeELZu97n1lxsVk02nW7444+X0pehsOTT5rNn+9OAGPGuAOprc3taKNH\nm5WXm/3v/3Z/zd697qD6xCdyE76mxuw973EBMZDa8Jtvuvddtar79OefdwfL/PmubOeea1ZaalZZ\nmVtL+exnzb76VddtVFHRfcdetsyF1oMPHly5XnnFlev11/uf1/PcCWHnTrMNG9wJ9ZZbXGB+73td\n5fU8s+98x+zoo11ZTz/d1SB7C84OL79s9vvfmy1f7rb1/sJk9Wr3nmVlZmec4U7iFRXuRPSjH7nu\nsro6sxEjeq/ppdNmP/6xW++77jL79383O/VU9/pjj3Xl/f3vu+8DjY1mo0a59e7p6afdyTC7hrt2\nrVv+8uW58//Xf7n5n3rKBfmjj7qW3AknuP3EzJ24FyxwtfnzznPb8v773fTbbnMn8xNPdNtg7lzX\nOrjwQheM997b/4l94UKzm2929+++2+ycc7qea2pywfUv/9L36zdtcie9z3zGlWfcOLMlS9xnfPrp\nZjfc4Ob72c/M3v/+rm15992u1e157mT7yU/2vvz6enfc3nOP2fTpA6txb9rkjqPCQrd+zzzjlrN6\ntQu/sjL3mf7wh66lYOZaXOPHm33/+7n7oOe5SsCMGa6ycPXVbt2fftrsnXd6L+Ott5qdfbZ77k9/\ncp97dpdjOm32+ONmX/mKq6iUlppNmeIqOd/+tqvMzpvXdwu/vt4F2XnnuRB46SV3fkok3G3lSlcx\n7qObk7wMh1WrXJ//lCmuayBbXZ2rbfamoaH/pB6o++93O+ScOW5HOPNMd9A//nj3Hau93bVITjyx\n6+S2ZInr++z4kK+7zgWJ57mdfvRosyeeGFi5HnnEbPLkvpvvqZQ7ECIRd6CNGuXmP+cc1x3305+6\nrrORI11tfeFC1/rats29vqXF1brPOKP3VtELL7gTwTnnmL33vW5nnjTJnfDeecfNU1PjThQf/ah7\n/sYb+25hdbj0UtcdkK2pyeyDH3QnrJ4n+lWrzP78575PRNde67oYs23b5k4mL76YO/+vf+1C67nn\nuqZ1VBJefbX7vJ5ndt997rkbbnD7xVVXde2LL73ktl887oL25ZfdaxIJt/2+8hV3QjvQsY7ly93x\n0dDgQnHZsu7P19W5CtTmzbmvff55Fwa33da1raqq3HY47TR3Yus4saZS7jN97DH3XuPHdwVmS4sL\n495autdc48bFPM8dBz27hDs0NLgW+9y5ZpdcYvbLX7qy/+xnblvefLOr0Nx/v1vO0Ue7fa1j/1m3\nzu13J57oKl7jx3f/vHrq6LK77z63b33pS+7148e7ysiCBe6z8jy37UaN6t4deckl7tg1c63ds892\nJ//vfc/sD3/I3ac9z7UcR49265BKdT23e7db7yuu2H94/t3f9dn6Ii/DoanJ9Wt2fBBBsWmTG8t4\n/nnXuunrYPY81+d54omumXvssd27fxIJ14S88EJ3svyf/zm0cn3ta24nz975zNzBd955rgZWV7f/\nZeza5boLvvhFV9POlk67k91JJ3Vfzo4drrb7hz90n3/FCnciLi93NbWyMndS/OUvc7tf+rJ8uQuZ\n7Fr0P/7BGYCwAAAHWklEQVSjO0B7rueB6OiO6Sh/Ou1q2IsX9/2a555zAXHjja47YsYMd5D35c03\n3Qmmt66+ji6rwXLWWS5wPv7x3p+/7jo3mJ2tpsadXJcsyZ3/nXfciarnxRdLlriLIL72NVfjzvbH\nP7rPKPs1W7a4z33rVvf4zjvdfp5t715XMSkrc889+6xrAS5Y4Grfs2fn9gx4ngvlntvQ81yQf+Yz\nXe85EHV1rmU0bZoLyfe/341XZauudoFx++1dlZz+WnlmrjJ72mkulC+/3FUITzrJVQr6a1WtWOH2\nwV4uQCEvw8HMNePeDVdE9KUjIEpKeu/vXr/eXQ3Vs6tqIDqu3LrySleLXLrUHbgzZ7qxkI5m96Hw\nPFf7njXLtYhSKXdyvf76vl/T0uIO6IG+//vf72qtZu7v1KmHduXYZZd1XRBw881u+/d3cNfUuFZi\nWZmraQbFE0+4Pv2+9p/du92J7O233WPPMzv/fLdPHqxzzzUrKur95HvFFa71ctNN7j0vvdT1t3fY\nu9eFckc3aiLh9ptLLnFB0lMi4e9xn0q5rsIvfKH3Xogf/chV9rLHYg7U+vUucE4+2exb3zrw7rbz\nz+917IG8DYcjgee5brHeBs4G286d7qCbO9c1dU85pf8rSg5WR1/ziSe6q8XOPPPAak4D9fDDrtWz\ndaurqQ3kgMz25puu9vbii64G3dHt1Z9k0pVlMEJ2sKTTXVfk9eUb33Bdhmau/DNn7n/sqC+bNrnu\n076sWOHGAUaOdNu156Xjl13mus08z5XnvPOGdr8ZSp53+K9aevVV143Y47ND4SCB4nlm3/ymO1kf\nyrXjByKRcLXS977XDZIPhvPOMyso6P97NEeCPXtc6+Evf3GheKjh2p/t23sfD1y61LX6vvtdN2bX\ns9tS+jd/vhsfzELAwmEk8BiwBlgNnAqUA0uAdcCzmXk6XAusB9YCH+ljmT5tbTkkA6mBDsT3v+/6\n1wcyztCb5ctzB7qPZIsXuy6hr37VvzJ4nhtHmDhx6CsUR6o//9ld/ZSFIQiHQ/mJ1weAF4H7gChQ\nAlwP7AJuAa4ByoCvAzOBh4D3AUcBzwEzAK/HMjPrKVVVVVRWVvpdjEDo3BZm7udMIsH9T25D7ZD2\ni7173U9v3HknFBUNarkOyl//CsOGwfTph7SYvD5GzNzPC2UE6Se7RwBn4IIBIAU0AOfjQoPM3wsy\n9xcADwNJYDOwAThlgO+dF6qqqvwuQmB0botQKK+DAQ5xvxg5Eu69199gAJgz55CDAfL8GDmAf5N7\nqAYaDlOAOuB+YDnwH7iWwzigNjNPbeYxwAQg+1frqnEtCBERCaCBhkMUOBm4K/O3Gdd9lK2/fjD1\nH4mIHGHGA9m/o/0B4Gnc4PT4zLQK3OAzuODIDo9ncAPYPW2gK1R000033XQ7sNsGAuRPuEFlgBtw\ng9AdA9HgwuAHmfszgRVAHNcltZHg/f9qEREZBCcBrwJvAI/jBqnLcVci9XYp63W4dFsL/M1hLamI\niIiIiBwZ5uNaFOvp6pY60kwCXgDeBFYBV2SmD+SLg3OBlZnnbh/SUg+tCPBX4MnM43zdFoP1hdIj\nYVtciztGVuK+G1VA/myL+3BXeWb/P+PBXPcC4NeZ6a8Axwxu8QdfBNfdNBmI4cYmjvezQENkPDA7\nc38Y8BZuPW8Brs5Mv4bccZoYbttsoGucZhld3xP5HS5c343+FXgQ+G3mcb5uiweAyzL3o7gu2nzc\nFpOBt3EnMXAnss+RP9viDGAO3cNhMNd9Ee4KU4CLgF8NaumHwP/DXb3UoeeVTUeqJ4AP41K/4/sg\n4+m6wutaureingFOw10FtiZr+sXAT4e0pENjIm586oN0tRzycVuMwJ0Qe8rHbVGOqzSV4ULySeAc\n8mtbTKZ7OAzmumdfJRrFfVetTwP9nsNgOgrYmvU4H74gNxlXQ1jKwX9xsOf0Gt6d2+s24Gt0/wmV\nfNwWg/WF0iNhW+wBbgW2ANuAvbgulXzcFh0Gc92zz7Udv2pR3tcbByEczO8CHGbDgP8C/gVo7PFc\nxzXLR7qPATtx4w19XdKcL9tiML5QeqSYBlyJqzxNwB0rn+0xT75si94c1nUPQjjU4AZrO0yie/Id\nSWK4YPhPXLcSuNpA9hcHd2bu99wuE3HbpSZzP3t6zRCVd6icjvsdrk2439z6EG6b5OO2qM7cXs08\nfgwXEjvIv20xD3gZ2I2r2T6O63bOx23RYTCOieqs1xydud8xtrVn8Is8eKK4L8VNxn1J7kgdkA4B\nv8B1p2QbyBcHl+L6DkO8ewbb+nIWXWMO+botBusLpe/2bXES7kq+Itw6PABcTn5ti8nkDkgP1rov\nAu7O3L+Yd8GANMBHcQNRG3ADLUeiD+D611fgulP+ivvQBvLFwY5L1TYAdwx1wYfYWXRdrZSv22Kw\nvlB6JGyLq+m6lPUBXGs7X7bFw7ixlgRubOBSBnfdC4BH6LqUdfIQrIOIiIiIiIiIiIiIiIiIiIiI\niIiIiIiIiIiIiMjQ+z/GJUnBtHf4OAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd38ba7e0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training error and validation error\n",
    "Xaxis = [x * 100 for x in range(training_iter/100)]\n",
    "plt.plot(Xaxis, train_error, 'r',label='train error')\n",
    "plt.plot(Xaxis, valid_error, 'g',label='validation error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 46)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set2 = numpy.reshape(test_set1, (test_set1.shape[0]*2, test_set1.shape[1]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape the W matrix to [23,10]\n",
    "W_1_prime = numpy.reshape(W_1,[23, n_hiddens[0]])\n",
    "hidden_1 = sess.run(tf.nn.sigmoid(numpy.matmul(test_set2,W_1_prime)+b_1))\n",
    "W_2_prime = numpy.reshape(W_2,[n_hiddens[0], n_hiddens[1]])\n",
    "hidden_2 = sess.run(tf.nn.sigmoid(numpy.matmul(hidden_1,W_2_prime)+b_2))\n",
    "W_3_prime = numpy.reshape(W_3,[n_hiddens[1], n_hiddens[2]])\n",
    "hidden_3 = tf.nn.sigmoid(numpy.matmul(hidden_2,W_3_prime)+b_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = sess.run(hidden_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate function\n",
    "def evaluateFunc(num, ori_set, new_set, nn, nNeighbor=100):\n",
    "    '''\n",
    "        num: the number of sample time series we use to evaluate the performance of our neural network model\n",
    "        ori_set: it is the original dataset\n",
    "        new_set: this is the dataset generated after we perform our neural network model on our original dataset\n",
    "        nn: the number of time series we use to calculate the dtw and euclidean distance\n",
    "        nNeighbor: the number of neighbors we extracted to compare the overlap between dtw and euclidean distances\n",
    "    '''\n",
    "    result = []\n",
    "    for n in range(num):\n",
    "        euclidean_dists = []\n",
    "        dtw_dists = []\n",
    "        for i in range(nn):\n",
    "            dtw_dists.append((i,dtw(ori_set[i], ori_set[nn + n])))\n",
    "            euclidean_dists.append((i, euclideanDist(new_set[i], new_set[nn + n])))\n",
    "        euclidean_dists_sorted = sorted(euclidean_dists, key=(lambda x: x[1]))\n",
    "        dtw_dists_sorted = sorted(dtw_dists, key=(lambda x: x[1]))\n",
    "        euclid_set = set()\n",
    "        dtw_set = set()\n",
    "        for i in range(nNeighbor):\n",
    "            euclid_set.add(euclidean_dists_sorted[i][0])\n",
    "            dtw_set.add(dtw_dists_sorted[i][0])\n",
    "        count = 0\n",
    "        for x in euclid_set:\n",
    "            if x in dtw_set:\n",
    "                count += 1\n",
    "        result.append(float(count)/nNeighbor)\n",
    "    return reduce(lambda x, y: x + y, result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perform = evaluateFunc(1000, test_set2, test_features, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47119\n"
     ]
    }
   ],
   "source": [
    "print perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with hidden layers defined as [100, 50], we get around 53.984% overlapping\n",
    "# with hidden layers defined as [100, 23], we get around 40.405%\n",
    "# with hidden layers defined as [100, 50, 23], we get around 40.646% overlapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
